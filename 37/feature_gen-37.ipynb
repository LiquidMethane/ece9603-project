{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3026a0d-1c0e-44f4-b142-63e27b436d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363b7ef7-b444-4d6d-bae8-dde65afc2846",
   "metadata": {},
   "source": [
    "### Modify the parameters before running\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f76c62-7005-4403-9e50-ee17689483ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_size = 21\n",
    "flattened_size = 777\n",
    "normal_feature_path = './data/features_norm_scaled.csv'\n",
    "anomaly_feature_path = './data/features_anom_scaled.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfaff5e-02ed-4dc8-8441-243dc39a4a24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209ece5-ae9f-4ce6-ab59-b8cde9e6600c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef326964-34fb-455c-936b-946dee0fdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.read_csv('sensor_scaled_cleaned.csv', index_col='index')\n",
    "\n",
    "# split out normal data for feature generation\n",
    "data_final_norm = data_final[data_final['machine_status'] == 'NORMAL']\n",
    "\n",
    "l = data_final_norm.shape[0]\n",
    "thread_size = l/8\n",
    "\n",
    "# supplemental function to check if indices in a window are consecutive\n",
    "def checkConsecutive(seq):\n",
    "    n = len(seq) - 1\n",
    "    return (sum(np.diff(seq) == 1) >= n)\n",
    "\n",
    "# define container for 8 threads\n",
    "normal_sample_0 = np.empty((0, flattened_size))\n",
    "normal_sample_1 = np.empty((0, flattened_size))\n",
    "normal_sample_2 = np.empty((0, flattened_size))\n",
    "normal_sample_3 = np.empty((0, flattened_size))\n",
    "normal_sample_4 = np.empty((0, flattened_size))\n",
    "normal_sample_5 = np.empty((0, flattened_size))\n",
    "normal_sample_6 = np.empty((0, flattened_size))\n",
    "normal_sample_7 = np.empty((0, flattened_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133e088e-2bfe-4df8-a03b-4ff780215977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions that will be run on each threads (sketchy but works)\n",
    "def construct_features_0():\n",
    "    global normal_sample_0\n",
    "    for idx in range(0, thread_size):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_0 = np.append(normal_sample_0, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_1():\n",
    "    global normal_sample_1\n",
    "    for idx in tqdm(range(thread_size+1, thread_size*2)):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_1 = np.append(normal_sample_1, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_2():\n",
    "    global normal_sample_2\n",
    "    for idx in range(thread_size*2+1, thread_size*3):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_2 = np.append(normal_sample_2, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_3():\n",
    "    global normal_sample_3\n",
    "    for idx in range(thread_size*3+1, thread_size*4):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_3 = np.append(normal_sample_3, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_4():\n",
    "    global normal_sample_4\n",
    "    for idx in range(thread_size*4+1, thread_size*5):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_4 = np.append(normal_sample_4, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_5():\n",
    "    global normal_sample_5\n",
    "    for idx in range(thread_size*5+1, thread_size*6):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_5 = np.append(normal_sample_5, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_6():\n",
    "    global normal_sample_6\n",
    "    for idx in range(thread_size*6+1, thread_size*7):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_6 = np.append(normal_sample_6, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n",
    "def construct_features_7():\n",
    "    global normal_sample_7\n",
    "    for idx in range(thread_size*7+1, thread_size*8):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            normal_sample_7 = np.append(normal_sample_7, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93721fe-c111-41d6-a348-ffa112a1ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multithreading to the moon\n",
    "import threading\n",
    "\n",
    "threads = []\n",
    "\n",
    "# construct threads\n",
    "t1 = threading.Thread(target=construct_features_0)\n",
    "t2 = threading.Thread(target=construct_features_1)\n",
    "t3 = threading.Thread(target=construct_features_2)\n",
    "t4 = threading.Thread(target=construct_features_3)\n",
    "t5 = threading.Thread(target=construct_features_4)\n",
    "t6 = threading.Thread(target=construct_features_5)\n",
    "t7 = threading.Thread(target=construct_features_6)\n",
    "t8 = threading.Thread(target=construct_features_7)\n",
    "\n",
    "# add threads to thread array\n",
    "threads.append(t1)\n",
    "threads.append(t2)\n",
    "threads.append(t3)\n",
    "threads.append(t4)\n",
    "threads.append(t5)\n",
    "threads.append(t6)\n",
    "threads.append(t7)\n",
    "threads.append(t8)\n",
    "\n",
    "# start all threads\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd00a02-20d2-40cb-bda3-d509aff795fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file\n",
    "with open(normal_feature_path, 'ab') as f:\n",
    "    np.savetxt(f, normal_sample_0, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_1, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_2, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_3, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_4, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_5, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_6, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_7, delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ccc22-c519-4178-b20b-02c735f4e2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61e621-7767-4695-b96e-dd8ef93fbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for all broken status\n",
    "broken_idx = [17155, 24510, 69318, 77790, 128040, 141131, 166440]\n",
    "\n",
    "anom_sample_0 = np.empty((0, flattened_size))\n",
    "anom_sample_1 = np.empty((0, flattened_size))\n",
    "anom_sample_2 = np.empty((0, flattened_size))\n",
    "anom_sample_3 = np.empty((0, flattened_size))\n",
    "anom_sample_4 = np.empty((0, flattened_size))\n",
    "anom_sample_5 = np.empty((0, flattened_size))\n",
    "anom_sample_6 = np.empty((0, flattened_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c4b2a-934d-4c0b-a0f1-782144fe1be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thought multithreading was needed but apparently not\n",
    "def construct_features_anom_0():\n",
    "    global anom_sample_0\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[0] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_0 = np.append(anom_sample_0, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_1():\n",
    "    global anom_sample_1\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[1] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_1 = np.append(anom_sample_1, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_2():\n",
    "    global anom_sample_2\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[2] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_2 = np.append(anom_sample_2, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_3():\n",
    "    global anom_sample_3\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[3] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_3 = np.append(anom_sample_3, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_4():\n",
    "    global anom_sample_4\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[4] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_4 = np.append(anom_sample_4, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_5():\n",
    "    global anom_sample_5\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[5] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_5 = np.append(anom_sample_5, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_6():\n",
    "    global anom_sample_6\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df.index >= broken_idx[6] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp.index.to_numpy()):\n",
    "            anom_sample_6 = np.append(anom_sample_6, temp.drop(['timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, flattened_size), axis=0)  \n",
    "        idx = idx + 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1139fa9c-4a8c-4cc8-a3b1-b20edf5e276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_features_anom_0()\n",
    "construct_features_anom_1()\n",
    "construct_features_anom_2()\n",
    "construct_features_anom_3()\n",
    "construct_features_anom_4()\n",
    "construct_features_anom_5()\n",
    "construct_features_anom_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5845f5b7-57ac-4a60-ba12-36bf55272b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(anomaly_feature_path, 'ab') as f:\n",
    "    np.savetxt(f, anom_sample_0, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_1, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_2, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_3, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_4, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_5, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_6, delimiter=',', newline='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
