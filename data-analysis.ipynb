{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c90f59-45f6-4b70-b7ed-676ad6ed6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b33a3091-8e13-432c-8c96-0e4beb6fa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "data = pd.read_csv('sensor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e3805-a823-45c9-b0ef-27d89a6d5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827f53d9-1f6e-4c16-963c-8bcac615ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 0 with NaN\n",
    "data = data.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb9d50-43f0-4d4a-8b9f-dd01bd453f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data volume\n",
    "msno.bar(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9d452-0715-4ca3-bdd8-b4d44cdc37c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data distribution\n",
    "msno.matrix(data, figsize=(25, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bca4bd-8707-443e-8ab1-688453f23e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out anomalous data\n",
    "data_anom = data[data.machine_status != 'NORMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a2738-4f23-4abc-a232-c9197a8e7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data volume\n",
    "msno.bar(data_anom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72d00a9-e23d-4373-acbd-fe5b54f5787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data distribution\n",
    "msno.matrix(data_anom, figsize=(25, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c542b7-4d7d-4ed2-bcc1-defefffea994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sensors with tooooooo many missing values\n",
    "data_col_reduced = data.drop(['sensor_00',\n",
    "                              'sensor_05', \n",
    "                              'sensor_06', \n",
    "                              'sensor_07', \n",
    "                              'sensor_08', \n",
    "                              'sensor_09', \n",
    "                              'sensor_11', \n",
    "                              'sensor_12', \n",
    "                              'sensor_13', \n",
    "                              'sensor_15',\n",
    "                              'sensor_50',   \n",
    "                              'sensor_51'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb5e84-3827-42d7-852f-65ecdd7e2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data again\n",
    "msno.bar(data_col_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d780f7-e2dc-427e-91f1-ebd942ba3914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr = data_col_reduced.drop(['index', 'timestamp', 'machine_status'], axis=1).corr()\n",
    "\n",
    "# # Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(25, 25))\n",
    "\n",
    "# Draw corr heatmap\n",
    "sns.heatmap(corr, annot=True, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be2b8ec1-df30-407b-be0e-63546ec4ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sensors that are toooooooo similar to each other\n",
    "data_col_reduced_final = data.drop(['sensor_00',\n",
    "                                    'sensor_05', \n",
    "                                    'sensor_06', \n",
    "                                    'sensor_07', \n",
    "                                    'sensor_08', \n",
    "                                    'sensor_09', \n",
    "                                    'sensor_11', \n",
    "                                    'sensor_12', \n",
    "                                    'sensor_13', \n",
    "                                    'sensor_15',\n",
    "                                    'sensor_16',\n",
    "                                    'sensor_19',\n",
    "                                    'sensor_21',\n",
    "                                    'sensor_50',   \n",
    "                                    'sensor_51'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b545df-808c-432a-bde1-6f3e15700c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all rows with NaN values\n",
    "data_final = data_col_reduced_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5689153-1493-4ec1-944a-3047d0c3e228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186014, 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shape of dataframe\n",
    "data_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13dbaa4a-bd05-41b8-a3c7-68de8c416dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NORMAL        171991\n",
       "RECOVERING     14016\n",
       "BROKEN             7\n",
       "Name: machine_status, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of labels\n",
    "data_final['machine_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4589c74-5ee3-4c97-9f8d-0a37eaa900b7",
   "metadata": {},
   "source": [
    "# DO NOT RUN BEYOND THIS CELL \n",
    "(your computer may collapse into a blackhole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57309c97-c262-42b9-98bb-e5d3442fefa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out normal data for feature generation\n",
    "data_final_norm = data_final[data_final['machine_status'] == 'NORMAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735e06e1-ee39-4b8a-95b3-d405363d2f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supplemental function to check if indices in a window are consecutive\n",
    "def checkConsecutive(seq):\n",
    "    n = len(seq) - 1\n",
    "    return (sum(np.diff(seq) == 1) >= n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c78251-6c62-4e31-a4dd-7c9245b2e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define window size and container for 8 threads\n",
    "window_size = 37\n",
    "\n",
    "normal_sample_0 = np.empty((0, 1369))\n",
    "normal_sample_1 = np.empty((0, 1369))\n",
    "normal_sample_2 = np.empty((0, 1369))\n",
    "normal_sample_3 = np.empty((0, 1369))\n",
    "normal_sample_4 = np.empty((0, 1369))\n",
    "normal_sample_5 = np.empty((0, 1369))\n",
    "normal_sample_6 = np.empty((0, 1369))\n",
    "normal_sample_7 = np.empty((0, 1369))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c398631c-e39a-49de-af36-9892d947c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions that will be run on each threads (sketchy but works)\n",
    "def construct_features_0():\n",
    "    global normal_sample_0\n",
    "    for idx in range(0, 21500):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_0 = np.append(normal_sample_0, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_1():\n",
    "    global normal_sample_1\n",
    "    for idx in range(21501, 43000):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_1 = np.append(normal_sample_1, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_2():\n",
    "    global normal_sample_2\n",
    "    for idx in range(43001, 64500):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_2 = np.append(normal_sample_2, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_3():\n",
    "    global normal_sample_3\n",
    "    for idx in range(64501, 86000):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_3 = np.append(normal_sample_3, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_4():\n",
    "    global normal_sample_4\n",
    "    for idx in range(86001, 107500):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_4 = np.append(normal_sample_4, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_5():\n",
    "    global normal_sample_5\n",
    "    for idx in range(107501, 129000):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_5 = np.append(normal_sample_5, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_6():\n",
    "    global normal_sample_6\n",
    "    for idx in range(129001, 150500):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_6 = np.append(normal_sample_6, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n",
    "def construct_features_7():\n",
    "    global normal_sample_7\n",
    "    for idx in range(150501, 171954):\n",
    "        temp = data_final_norm.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            normal_sample_7 = np.append(normal_sample_7, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d40d4c43-ce84-4274-bacb-698340388226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multithreading to the moon\n",
    "import threading\n",
    "\n",
    "threads = []\n",
    "\n",
    "# construct threads\n",
    "t1 = threading.Thread(target=construct_features_0)\n",
    "t2 = threading.Thread(target=construct_features_1)\n",
    "t3 = threading.Thread(target=construct_features_2)\n",
    "t4 = threading.Thread(target=construct_features_3)\n",
    "t5 = threading.Thread(target=construct_features_4)\n",
    "t6 = threading.Thread(target=construct_features_5)\n",
    "t7 = threading.Thread(target=construct_features_6)\n",
    "t8 = threading.Thread(target=construct_features_7)\n",
    "\n",
    "# add threads to thread array\n",
    "threads.append(t1)\n",
    "threads.append(t2)\n",
    "threads.append(t3)\n",
    "threads.append(t4)\n",
    "threads.append(t5)\n",
    "threads.append(t6)\n",
    "threads.append(t7)\n",
    "threads.append(t8)\n",
    "\n",
    "# start all threads\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10e202e5-54fd-4feb-a13f-f56f5f8b96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a file\n",
    "with open('features.csv', 'ab') as f:\n",
    "    np.savetxt(f, normal_sample_0, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_1, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_2, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_3, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_4, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_5, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_6, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, normal_sample_7, delimiter=',', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d7d9f-ab3a-4942-94d0-09ae4f04b65a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98103cf-ef54-4994-a33e-5ac3731c19d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19d84f96-d1f3-408f-9a70-2f70094f7e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices for all broken status\n",
    "broken_idx = [17155, 24510, 69318, 77790, 128040, 141131, 166440]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3a87b73d-4083-4250-8cd8-22ea58994a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define window size and container for each thread again\n",
    "window_size = 37\n",
    "\n",
    "anom_sample_0 = np.empty((0, 1369))\n",
    "anom_sample_1 = np.empty((0, 1369))\n",
    "anom_sample_2 = np.empty((0, 1369))\n",
    "anom_sample_3 = np.empty((0, 1369))\n",
    "anom_sample_4 = np.empty((0, 1369))\n",
    "anom_sample_5 = np.empty((0, 1369))\n",
    "anom_sample_6 = np.empty((0, 1369))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce5dbba9-9f62-41db-896b-09d86094c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thought multithreading was needed but apparently not\n",
    "def construct_features_anom_0():\n",
    "    global anom_sample_0\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[0] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_0 = np.append(anom_sample_0, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_1():\n",
    "    global anom_sample_1\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[1] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_1 = np.append(anom_sample_1, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_2():\n",
    "    global anom_sample_2\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[2] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_2 = np.append(anom_sample_2, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_3():\n",
    "    global anom_sample_3\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[3] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_3 = np.append(anom_sample_3, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_4():\n",
    "    global anom_sample_4\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[4] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_4 = np.append(anom_sample_4, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_5():\n",
    "    global anom_sample_5\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[5] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_5 = np.append(anom_sample_5, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "        \n",
    "        \n",
    "def construct_features_anom_6():\n",
    "    global anom_sample_6\n",
    "    global broken_idx\n",
    "    \n",
    "    temp_anom = data_final.loc[lambda df: df['index'] >= broken_idx[6] - window_size + 1, :]\n",
    "    idx = 0\n",
    "    \n",
    "    while temp_anom.iloc[idx+window_size-1]['machine_status'] != 'NORMAL':\n",
    "        temp = temp_anom.iloc[idx: idx + window_size]\n",
    "        if checkConsecutive(temp['index'].to_numpy()):\n",
    "            anom_sample_6 = np.append(anom_sample_6, temp.drop(['index', 'timestamp', 'machine_status'], axis=1).to_numpy().reshape(1, 1369), axis=0)  \n",
    "        idx = idx + 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfeaecde-167f-4446-9014-1bd1f1609075",
   "metadata": {},
   "outputs": [],
   "source": [
    "construct_features_anom_0()\n",
    "construct_features_anom_1()\n",
    "construct_features_anom_2()\n",
    "construct_features_anom_3()\n",
    "construct_features_anom_4()\n",
    "construct_features_anom_5()\n",
    "construct_features_anom_6()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c21b4ef-d8c5-47a2-9dab-47b198d443b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features_anom.csv', 'ab') as f:\n",
    "    np.savetxt(f, anom_sample_0, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_1, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_2, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_3, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_4, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_5, delimiter=',', newline='\\n')\n",
    "    np.savetxt(f, anom_sample_6, delimiter=',', newline='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe9e212-7369-4a2f-b740-5529c458e53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
